# üß† AI-Powered RAG System üîç  
**Deployable Offline | On-Premise | Any Cloud**  

This project showcases a **Retrieval-Augmented Generation (RAG) system** designed for **flexibility, scalability, and real-world deployment**. 

Powered by **Azure AI Containers**, it ensures **high-performance retrieval, accuracy, and security**‚Äîwhether running **fully offline, or in any cloud environment**.

## **Why This Matters?**

**Hybrid Retrieval**: Combines **Qdrant (vector search)**, **BM25 (keyword matching)**, and **Ollama embeddings** to enhance ranking and accuracy.  

**Multilingual AI**: Supports **Arabic & English** with optimized retrieval for short queries and complex prompts.  

**Azure AI Integration**: Leverages **Azure AI Containers** for ensuring **better accuracy, security, and usability**‚Äîeven in offline environments.  

**On-Premise Ready**: Designed for **full offline deployment**, making it ideal for **customers needing secure, cloud-independent AI solutions**.  

---

## üöÄ How Azure AI Containers can Enhance Offline RAG System

Azure AI Containers enable **advanced AI capabilities** while keeping the system **fully offline and on-premise-ready**. 

These services enhance **document processing, query understanding, and response generation**, making the system **more accurate, secure, and scalable**.

### **Improving Document Processing & Indexing**
- **Azure AI Vision - Read** ‚Üí Extracts text from scanned documents & images, making PDFs and handwritten content searchable.  
- **Document Intelligence** ‚Üí Processes structured documents (invoices, contracts) before indexing, improving retrieval in legal and enterprise use cases.  

### **Enhancing Query Understanding & Retrieval**
-  **Azure AI Language** ‚Üí Detects **query language**
- **Conversational Language Understanding (CLU)** ‚Üí Classifies **query intent** (e.g., **search vs. summarization**) for smarter responses.  

### **Enhancing AI-Generated Responses**
- **Sentiment Analysis** ‚Üí Adjusts AI response tone (formal/casual).  
- **Text Translation** ‚Üí Enables **cross-language retrieval** (Arabic query ‚Üí English documents).  
- **Neural Text-to-Speech** ‚Üí Converts AI responses into voice for **future chatbot integrations**.  

### **Ensuring Content Safety & Compliance**  
- **Azure AI Content Safety** ‚Üí Scans both **text and images** for **violence, hate speech, self-harm, and explicit content**, ensuring **AI-generated responses and retrieved documents comply with safety standards**.  

üîπ **These integrations ensure the RAG system remains fully functional in offline environments while benefiting from enterprise-grade AI.**  

üìå **Learn More**: [Azure AI Containers](https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-container-support)  
üìå **Azure AI Content Safety**: [Content Safety Containers (Preview)](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/containers/container-overview)  

---

## üèó Enhanced User Flow with Azure AI Containers  

| **Step** | **Tool Used** | **Description** |
|----------|-------------|----------------|
| **1. User enters or speaks a query** | Streamlit UI + **Azure AI Speech** | Users can either **type** or **speak** their query. |
| **2. Spellcheck query** | **Bergamot (Local Spellchecker)** | Fixes **typos** before processing the query. |
| **3. Detect query language** | **Azure AI Language** | Determines whether the query is in **Arabic or English**. |
| **4. Translate query (if needed)** | **Azure Translator** | Converts **non-Arabic/English queries** into a supported language. |
| **5. Generate query embedding** | **Ollama (`bge-m3` and `arabert` )** | Converts the query into a **numerical vector representation**. |
| **6. Retrieve relevant documents** | **Qdrant (Vector DB)** | Performs a **hybrid search**: **vector similarity search** (embeddings) + **BM25 keyword match**. |
| **7. Rank retrieved documents** | **BM25 (Rank-BM25) + `bge-m3`** | Ranks results based on **keyword relevance** and **vector similarity**. |
| **8. Extract named entities (Optional)** | **Azure AI NER** | Identifies **key entities** in the query to improve retrieval precision. |
| **9. Apply OCR for document parsing** | **Azure Document Intelligence** | Extracts **text from scanned PDFs, images, or structured documents** to improve knowledge base ingestion. |
| **10. Summarize long documents (Optional)** | **Azure Text Summarization** | Summarizes **retrieved long documents** before passing to the LLM. |
| **11. Generate an AI response** | **Ollama (`Qwen/Gemma`)** | Uses an **LLM to generate an answer** using the **top-ranked documents** as context. |
| **12. Apply content safety filters** | **Azure AI Content Safety** | Ensures the **AI-generated response** follows safety guidelines, filtering out **harmful or inappropriate content**. |
| **13. Display response** | **Streamlit UI** | Shows **retrieved documents, scores, and final AI response**. |

---
## üõ†Ô∏è **Setup & Installation**  

### **1Ô∏è‚É£ Clone the Repository**
```bash
git clone https://github.com/your-repo/edge-rag.git
cd edge-rag
```

### **2Ô∏è‚É£ Set Up Python Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate   # Windows
```

### **3Ô∏è‚É£ Install Dependencies**
```bash
pip install -r requirements.txt
docker compose up -d
```

### **4Ô∏è‚É£ Start Qdrant (Vector Database)**
Make sure **Docker** is installed, then run:
```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### **5Ô∏è‚É£ Install & Run Ollama**
Follow Ollama installation from [Ollama's official website](https://ollama.com). Then, pull the required models:
```bash
ollama serve 
ollama pull qwen2.5:0.5b
ollama pull gemma2:2b
ollama pull bge-m3
ollama pull jaluma/arabert-all-nli-triplet-matryoshka:latest 
```

### **6Ô∏è‚É£ Run Azure AI Containers for Language Detection**
#### **Language Detection**
```bash
docker run --rm -it --platform linux/amd64 -p 5000:5000 --memory 6g --cpus 2 \
  mcr.microsoft.com/azure-cognitive-services/textanalytics/language \
  Eula=accept \
  Billing="$AZURE_LANGUAGE_BILLING_URL" \
  ApiKey="$AZURE_LANGUAGE_API_KEY"
```

```
curl -X POST "http://localhost:5000/text/analytics/v3.1/languages" \
     -H "Content-Type: application/json" \
     -d '{
          "documents": [
            {"id": "1", "text": "Hello, how are you?"},
            {"id": "2", "text": "ŸÖÿ±ÿ≠ÿ®ÿß ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü"}
          ]
        }'
```

### **7Ô∏è‚É£ Prepare & Index Documents**
Store your dataset inside the `data/` folder, then run:
```bash
python src/index_documents.py
```

Verify if the Qdrant Collections Exist
```
curl -X GET "http://localhost:6333/collections"
```

Clean Qdrant Collections if needed. 
```
curl -X DELETE "http://localhost:6333/collections/rag_docs_en"
curl -X DELETE "http://localhost:6333/collections/rag_docs_ar"
```

### **8Ô∏è‚É£ Start the Streamlit UI**
```bash
streamlit run src/streamlit_app.py
```

### **9Ô∏è‚É£ Test Queries**
Open your browser at `http://localhost:8501` and enter any query.  
Examples:  
- **English:** `"What is artificial intelligence?"`  
- **Arabic:** `"ŸÖÿß ŸáŸà ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿü"`

---
## üìå **Addressing Arabic Language Challenges**

1Ô∏è‚É£ Challenge: Arabic Ranker Models**

**Problem:** Many ranker models struggle to reconstruct answers when the supporting information is scattered across multiple chunks.  
**Solution:** We integrate **BM25 + bge-m3 reranker**, which improves the ranking of relevant Arabic documents based on **semantic similarity and keyword matching**.

2Ô∏è‚É£ Challenge: Arabic Embedding Models**

**Problem:** Single-word Arabic queries sometimes fail to retrieve results, even when relevant content exists in the knowledge base.  
**Solution:** We use a **hybrid search approach**, combining:
   - **Vector search (Ollama embeddings)**
   - **BM25 keyword matching**
   - **Reranking using bge-m3**
   This ensures better retrieval even for **short Arabic queries**.


3Ô∏è‚É£ Mitigating those Issues** 

Our current implementation mitigates these issues with:
  - Hybrid Search (BM25 + Vectors)
  - Re-ranking (bge-m3)
  - Named Entity Recognition (NER)
  - LLM Context Expansion

4Ô∏è‚É£ Future Improvements
-  **Experiment with specialized Arabic embedding models** (e.g., Arabic-trained versions of BGE or ARABERT).  
-  **Optimize BM25 weights for Arabic vs. English separately** to fine-tune ranking balance.  
-  **Extend Named Entity Recognition (NER) to improve keyword-based lookup**.  
-  **Benchmark different Arabic language models for better retrieval performance**.

---
Enjoy building your **production-ready RAG system**! üèóÔ∏èüî•  